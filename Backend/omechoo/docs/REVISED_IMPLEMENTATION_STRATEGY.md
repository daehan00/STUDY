# Omechoo 백엔드 전략: API 검색 + 실시간 정보 크롤링 (DB 최소화)

사용자의 의견을 반영하여, **식당 데이터를 직접 적재하지 않고(No-DB for Restaurants)** 외부 플랫폼(카카오맵)의 데이터를 적극 활용하는 **"On-Demand Scraping"** 방식으로 전략을 수정합니다.

---

## 1. 핵심 변경 사항

| 구분 | 기존 제안 (DB 중심) | **수정된 전략 (크롤링 중심)** |
| :--- | :--- | :--- |
| **식당 데이터** | DB에 저장 및 관리 (`restaurants` 테이블) | **저장 안 함.** API 결과 + 실시간 크롤링 정보 조합. |
| **상세 정보** | DB 데이터 또는 사용자 피드백 의존 | **카카오맵 상세 페이지 크롤링** (영업시간, 상세 메뉴, 리뷰 등). |
| **피드백** | 사용자 피드백 시스템 구축 | **제거.** 플랫폼(카카오/네이버)의 리뷰 데이터 활용. |
| **속도/성능** | DB 조회로 빠름 | 크롤링 오버헤드 존재 → **단기 캐싱(Redis/Memory)**으로 보완. |

---

## 2. 구현 아키텍처 (Phase 1.5)

### A. 메뉴 추천 (기존 유지)
*   In-memory / CSV 기반 추천 로직 유지.

### B. 식당 검색 (API + Crawling)
사용자 경험을 해치지 않으면서 정보를 제공하기 위해 **2단계 로딩** 방식을 제안합니다.

#### Step 1: 목록 검색 (Light) - 빠름
*   **동작:** 사용자가 추천 메뉴로 식당 검색 요청.
*   **처리:** 백엔드가 카카오 Local API를 호출.
*   **반환:** 식당 이름, 위치(위경도), 전화번호, **상세 페이지 URL(Place URL)** 등 기본 정보만 즉시 반환.
*   **UI:** 지도에 핀을 찍고 리스트를 보여줌.

#### Step 2: 상세 정보 (Deep) - 크롤링
*   **동작:** 사용자가 리스트에서 특정 식당을 클릭하거나, "상세 보기"를 요청.
*   **처리:**
    1.  백엔드는 해당 식당의 `Place URL`로 접속 (HTTP Request).
    2.  HTML 파싱 (`BeautifulSoup` 등 활용)하여 필요한 정보 추출.
        *   *추출 데이터 예시:* **실제 영업 시간**, **브레이크 타임**, **대표 메뉴 및 가격**, **별점/리뷰 수**.
    3.  추출된 데이터를 JSON으로 가공하여 반환.
*   **캐싱 (필수):** 크롤링 속도 저하(약 1~2초 소요)와 외부 차단을 방지하기 위해, 한 번 크롤링한 데이터는 **메모리(Redis 등)에 일정 시간(예: 12~24시간) 동안 캐싱**.

---

## 3. 필요 기술 및 라이브러리

1.  **Web Scraper:**
    *   `httpx` (비동기 HTTP 클라이언트) + `BeautifulSoup4` (HTML 파서).
    *   *참고:* 카카오맵 상세 페이지가 동적으로 렌더링되는 부분이 많을 경우 `playwright` 같은 Headless Browser가 필요할 수 있으나, 초기에는 가벼운 `httpx`로 시도 권장.
2.  **Caching:**
    *   `Redis` (권장) 또는 Python `lru_cache` (단일 인스턴스일 경우).
    *   목적: 동일 식당 중복 크롤링 방지.

---

## 4. 백엔드 개발 리스트 (To-Do)

### 기능 1: 식당 상세 정보 크롤러 (`RestaurantScraper`)
*   [ ] `Place URL`을 입력받아 HTML을 가져오는 기능.
*   [ ] HTML에서 다음 정보를 추출하는 파서 구현:
    *   영업 상태 (영업중/영업종료)
    *   영업 시간 텍스트
    *   메뉴 리스트 (가격 포함)
    *   후기 평점

### 기능 2: 캐싱 레이어 (`CacheService`)
*   [ ] Key-Value 형태로 식당 ID(혹은 URL)와 크롤링 결과를 저장/조회.
*   [ ] TTL(만료 시간) 설정 (예: 24시간).

### 기능 3: API 엔드포인트 확장
*   [ ] `GET /api/restaurant/{restaurant_id}/detail`: 크롤링 수행 및 상세 정보 반환.

---

## 5. 장단점 분석

*   **장점:**
    *   **관리 비용 Zero:** 식당 폐업, 메뉴 변경 등을 DB에 업데이트할 필요 없음.
    *   **풍부한 정보:** API로는 알 수 없는 '영업 시간', '구체적 메뉴' 제공 가능.
*   **단점 및 리스크:**
    *   **법적/약관 이슈:** 과도한 크롤링은 서비스 차단 사유가 될 수 있음 (적당한 텀을 두고 요청, 캐싱 적극 활용 필요).
    *   **구조 변경 취약:** 카카오맵 웹페이지 구조가 바뀌면 크롤러 코드를 수정해야 함.
    *   **속도:** API보다 느림 (사용자에게 로딩 인디케이터 필요).

이 전략은 **"식당 데이터 관리는 하기 싫지만, 사용자에게는 양질의 정보를 주고 싶은"** 현재의 니즈에 가장 부합하는 현실적인 방안입니다.